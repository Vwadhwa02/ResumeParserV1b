{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinanceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading yfinance-0.2.13-py2.py3-none-any.whl (59 kB)\n",
      "     -------------------------------------- 59.3/59.3 kB 522.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (1.23.4)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (2.28.2)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Collecting lxml>=4.9.1\n",
      "  Downloading lxml-4.9.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting appdirs>=1.4.4\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (2022.6)\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.3.6.tar.gz (35 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cryptography>=3.3.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yfinance) (39.0.2)\n",
      "Collecting beautifulsoup4>=4.11.1\n",
      "  Downloading beautifulsoup4-4.12.0-py3-none-any.whl (132 kB)\n",
      "     ------------------------------------ 132.2/132.2 kB 975.9 kB/s eta 0:00:00\n",
      "Collecting html5lib>=1.1\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "     -------------------------------------- 112.2/112.2 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26->yfinance) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "Building wheels for collected packages: frozendict\n",
      "  Building wheel for frozendict (setup.py): started\n",
      "  Building wheel for frozendict (setup.py): finished with status 'done'\n",
      "  Created wheel for frozendict: filename=frozendict-2.3.6-py3-none-any.whl size=13628 sha256=feed2f42bce4bc63ea068a3d7963c38a1c778cbf171311b8f23e704cf0ae0c25\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\6c\\61\\5d\\1f026b2abdbbc5dc03a3fd9d0b54d76ebe8f8e5f466a2308fe\n",
      "Successfully built frozendict\n",
      "Installing collected packages: webencodings, multitasking, appdirs, soupsieve, lxml, html5lib, frozendict, beautifulsoup4, yfinance\n",
      "Successfully installed appdirs-1.4.4 beautifulsoup4-4.12.0 frozendict-2.3.6 html5lib-1.1 lxml-4.9.2 multitasking-0.0.11 soupsieve-2.4 webencodings-0.5.1 yfinance-0.2.13\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from pdfminer.high_level import extract_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\PROJECT\\P AI 1\\Untitled-1.ipynb Cell 3\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# pdf='True‪C:\\Users\\ADMIN\\Downloads\\Resume.pdf'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# pat=os.getcwd()+pdf\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m res\u001b[39m=\u001b[39mextract_text(\u001b[39m\"\u001b[39m\u001b[39mCV.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#if resume in docx\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# import docx2txt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# txt=docx2txt.process(pdf)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# txt=txt.replace('\\t',' ')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_text' is not defined"
     ]
    }
   ],
   "source": [
    "# pdf='True‪C:\\Users\\ADMIN\\Downloads\\Resume.pdf'\n",
    "# pat=os.getcwd()+pdf\n",
    "res=extract_text(\"CV.pdf\")\n",
    "\n",
    "\n",
    "#if resume in docx\n",
    "# import docx2txt\n",
    "# txt=docx2txt.process(pdf)\n",
    "# txt=txt.replace('\\t',' ')\n",
    "\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting fields from Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Software Developer', 'Certified Developer Java', 'Developer Proficient', 'Enthusiast Android Developer', 'Badminton Competitive', 'Rubik', 'Python', 'C Enterprise', 'Spring MVC', 'Mockito DBMS MySQL', 'Mongo DB Data', 'Json', 'Systems Windows', 'Ubuntu Web', 'Apache Tomcat Web Services', 'Jira', 'Postman Eclipse', 'Tata Consultancy Services Pvt', 'Developed', 'Databases Wrote Unit', 'Docker', 'Jira', 'Jaypee Institute', 'Noida CGPA', 'Science Ryan International School', 'Evolutionary Intelligence', 'Developer', 'Data Structures Coding Ninjas', 'Android Developer', 'Mean Personality Measure', 'Spam Detection', 'Optimal Sizing', 'Hybrid Energy', 'Deep Reinforcement Learning', 'Buzz Detection']\n"
     ]
    }
   ],
   "source": [
    "#extracting name\n",
    "person_name=[]\n",
    "for s in nltk.sent_tokenize(res):\n",
    "    for c in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(s))):\n",
    "        if hasattr(c,'label') and c.label()=='PERSON':\n",
    "            person_name.append(' '.join(cl[0] for cl in c.leaves()))\n",
    "\n",
    "#person_name=str(person_name)\n",
    "print(person_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jaibatra8@gmail.com']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "EMAIL_REF = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "re.findall(EMAIL_REF,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Python', 'Machine learning', 'C'}\n"
     ]
    }
   ],
   "source": [
    "SKILLS_DB = [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'English',\n",
    "    'Data Structures',\n",
    "    \"Java\",\n",
    "    'c',\n",
    "    'sql'\n",
    "]\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "word_tokens = nltk.tokenize.word_tokenize(res)\n",
    " \n",
    "    # remove the stop words\n",
    "filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "for token in filtered_tokens:\n",
    "    if token.lower() in SKILLS_DB:\n",
    "        found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "for ngram in bigrams_trigrams:\n",
    "    if ngram.lower() in SKILLS_DB:\n",
    "        found_skills.add(ngram)\n",
    "\n",
    "print(found_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid authentication credentials",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\PROJECT\\P AI 1\\Untitled-1.ipynb Cell 8\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# we search for each token in our skills database\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m filtered_tokens:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m skill_exists(token\u001b[39m.\u001b[39;49mlower()):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         found_skills\u001b[39m.\u001b[39madd(token)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# we search for each bigram and trigram in our skills database\u001b[39;00m\n",
      "\u001b[1;32me:\\PROJECT\\P AI 1\\Untitled-1.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(result) \u001b[39m&\u001b[39mgt; \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m result[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m skill\u001b[39m.\u001b[39mlower()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/PROJECT/P%20AI%201/Untitled-1.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(result\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mException\u001b[0m: Invalid authentication credentials"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "def skill_exists(skill):\n",
    "    url = f'https://api.apilayer.com/skills?q={skill}&amp;count=1'\n",
    "    headers = {'apikey': 'YOUR API KEY'}\n",
    "    response = request.request('GET', url, headers=headers)\n",
    "    result = response.json()\n",
    " \n",
    "    if response.status_code == 200:\n",
    "        return len(result) &gt; 0 and result[0].lower() == skill.lower()\n",
    "    raise Exception(result.get('message'))\n",
    " \n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "word_tokens = nltk.tokenize.word_tokenize(res)\n",
    " \n",
    "    # remove the stop words\n",
    "filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "for token in filtered_tokens:\n",
    "    if skill_exists(token.lower()):\n",
    "        found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "for ngram in bigrams_trigrams:\n",
    "    if skill_exists(ngram.lower()):\n",
    "        found_skills.add(ngram)\n",
    "\n",
    "print( found_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vaibhav Wadhwa', 'ME', 'SOFT', 'SKILLS Adaptability Communication Cooperation Fast Learner Organizational Positivity Problem', 'Technology', 'UNIVERSITY', 'DELHI', 'Senior', 'CBSE', 'CBSE', 'EXPERIENCE Volunteer', 'Sachkhand Foundation', 'Eco', 'Social Outreach Club', 'PROJECT Sentimental Analysis', 'Amazon Kindle', 'TextBlob', 'LANGUAGES English Hindi Punjabi']\n",
      "{'LANGUAGES English Hindi Punjabi', 'Vaibhav Wadhwa', 'DELHI', 'Sachkhand Foundation', 'TextBlob', 'SOFT', 'Social Outreach Club', 'Technology', 'Eco', 'Amazon Kindle', 'EXPERIENCE Volunteer', 'ME', 'CBSE', 'UNIVERSITY', 'PROJECT Sentimental Analysis', 'Senior', 'SKILLS Adaptability Communication Cooperation Fast Learner Organizational Positivity Problem'}\n"
     ]
    }
   ],
   "source": [
    "from operator import gt\n",
    "\n",
    "\n",
    "Reserve=[\n",
    "    'school',\n",
    "    'university',\n",
    "    'board',\n",
    "    'institute',\n",
    "    'college',\n",
    "    'academy',\n",
    "    'polytechnic',\n",
    "    'faculty',\n",
    "    \"ggsipu\",\n",
    "    'Graduation',\n",
    "    'High School',\n",
    "    'Senior Secondary',\n",
    "    'CBSE',\n",
    "]\n",
    "organizations = []\n",
    "for sent in nltk.sent_tokenize(res):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
    "                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n",
    "education=set()\n",
    "for o in organizations:\n",
    "     for w in Reserve:\n",
    "          if w.lower().find(w):\n",
    "               education.add(o)\n",
    "print(organizations)\n",
    "print(education)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
